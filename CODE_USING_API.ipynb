{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "38aguLA5PTj8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: instaloader in c:\\users\\graphene\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.10.2)\n",
            "Requirement already satisfied: requests>=2.4 in c:\\users\\graphene\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from instaloader) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\graphene\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.4->instaloader) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\graphene\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.4->instaloader) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\graphene\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.4->instaloader) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\graphene\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.4->instaloader) (2023.11.17)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install instaloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Username: rusharavichandran\n",
            "Full Name: Rusha ravichandran\n",
            "Biography: \n",
            "Followers: 120\n",
            "Following: 169\n",
            "Is Private: True\n",
            "Is Verified: False\n",
            "Is Business Account: False\n"
          ]
        }
      ],
      "source": [
        "#COLLECTING BASIC DATA\n",
        "import instaloader\n",
        "\n",
        "def check_instagram_account(username):\n",
        "    L = instaloader.Instaloader()\n",
        "\n",
        "    try:\n",
        "        profile = instaloader.Profile.from_username(L.context, username)\n",
        "        print(f\"Username: {profile.username}\")\n",
        "        print(f\"Full Name: {profile.full_name}\")\n",
        "        print(f\"Biography: {profile.biography}\")\n",
        "        print(f\"Followers: {profile.followers}\")\n",
        "        print(f\"Following: {profile.followees}\")\n",
        "        print(f\"Is Private: {profile.is_private}\")\n",
        "        print(f\"Is Verified: {profile.is_verified}\")\n",
        "        print(f\"Is Business Account: {profile.is_business_account}\")\n",
        "    except instaloader.exceptions.ProfileNotExistsException:\n",
        "        print(f\"The Instagram account '{username}' does not exist.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Get username input from the user\n",
        "username_to_check = input(\"Enter the Instagram username to check: \")\n",
        "check_instagram_account(username_to_check)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IonsOZpJLr7D",
        "outputId": "289c9bc2-9117-4da9-962d-54324099ad12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Username: christy_050505\n",
            "Full Name: Christina\n",
            "Number of Posts: 1\n",
            "Number of Followers: 112\n",
            "Number of Following: 125\n"
          ]
        }
      ],
      "source": [
        "#COLLECTING DATA FROM API\n",
        "import requests\n",
        "\n",
        "# Take username as input from the user\n",
        "name = input(\"Enter the Instagram username: \")\n",
        "\n",
        "url = \"https://instagram130.p.rapidapi.com/account-info\"\n",
        "\n",
        "querystring = {\"username\": name}\n",
        "\n",
        "headers = {\n",
        "    \"X-RapidAPI-Key\": \"c1121ad9edmsh28a3e1ba931dcf9p10b968jsnd61824ad3d31\",\n",
        "    \"X-RapidAPI-Host\": \"instagram130.p.rapidapi.com\"\n",
        "}\n",
        "\n",
        "response = requests.get(url, headers=headers, params=querystring)\n",
        "\n",
        "data = response.json()\n",
        "\n",
        "# Extract and print relevant information\n",
        "if \"username\" in data:\n",
        "    print(f\"Username: {data['username']}\")\n",
        "    print(f\"Full Name: {data['full_name']}\")\n",
        "    print(f\"Number of Posts: {data['edge_owner_to_timeline_media']['count']}\")\n",
        "    print(f\"Number of Followers: {data['edge_followed_by']['count']}\")\n",
        "    print(f\"Number of Following: {data['edge_follow']['count']}\")\n",
        "else:\n",
        "    print(\"User not found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NNkaqTrF_cm"
      },
      "outputs": [],
      "source": [
        "#USING API TO GET BASIC DETAILS\n",
        "import requests\n",
        "\n",
        "name = input(\"Enter username:\")\n",
        "url = \"https://instagram130.p.rapidapi.com/account-info\"\n",
        "\n",
        "querystring = {\"username\": name}\n",
        "\n",
        "headers = {\n",
        "    \"X-RapidAPI-Key\": \"c1121ad9edmsh28a3e1ba931dcf9p10b968jsnd61824ad3d31\",\n",
        "    \"X-RapidAPI-Host\": \"instagram130.p.rapidapi.com\"\n",
        "}\n",
        "\n",
        "response = requests.get(url, headers=headers, params=querystring)\n",
        "data = response.json()\n",
        "\n",
        "# Extracting information from the JSON response\n",
        "username = data.get(\"username\", \"N/A\")\n",
        "followers = data.get(\"edge_followed_by\", {}).get(\"count\", \"N/A\")\n",
        "following = data.get(\"edge_follow\", {}).get(\"count\", \"N/A\")\n",
        "description = data.get(\"biography\", \"N/A\")\n",
        "\n",
        "# Print the extracted information\n",
        "print(f\"Username: {username}\")\n",
        "print(f\"Followers: {followers}\")\n",
        "print(f\"Following: {following}\")\n",
        "print(f\"Description: {description}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbSxZyoaZpcq"
      },
      "outputs": [],
      "source": [
        "#GETTING SPECIFIC DATA FROM API\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "def process_data(api_response):\n",
        "    # Extract relevant information\n",
        "    ai_agent_type = api_response.get('ai_agent_type')\n",
        "\n",
        "    # Extract bio links\n",
        "    bio_links = []\n",
        "    if 'bio_links' in api_response:\n",
        "        bio_links = api_response['bio_links']\n",
        "\n",
        "    # Extract Facebook profile biolink\n",
        "    fb_profile_biolink = api_response.get('fb_profile_biolink')\n",
        "\n",
        "    blocked_by_viewer = api_response.get('blocked_by_viewer', False)\n",
        "    country_block = api_response.get('country_block', False)\n",
        "    external_url = api_response.get('external_url')\n",
        "    external_url_linkshimmed = api_response.get('external_url_linkshimmed')\n",
        "    full_name = api_response.get('full_name')\n",
        "    has_clips = api_response.get('has_clips', False)\n",
        "    highlight_reel_count = api_response.get('highlight_reel_count')\n",
        "    is_professional_account = api_response.get('is_professional_account', False)\n",
        "    category_enum = api_response.get('category_enum')\n",
        "\n",
        "    return ai_agent_type, bio_links, fb_profile_biolink, blocked_by_viewer, country_block, external_url, external_url_linkshimmed, full_name, has_clips, highlight_reel_count, is_professional_account, category_enum\n",
        "\n",
        "# Example usage\n",
        "name = \"themastertrades\"\n",
        "url = \"https://instagram130.p.rapidapi.com/account-info\"\n",
        "\n",
        "querystring = {\"username\": name}\n",
        "\n",
        "headers = {\n",
        "    \"X-RapidAPI-Key\": \"c1121ad9edmsh28a3e1ba931dcf9p10b968jsnd61824ad3d31\",\n",
        "    \"X-RapidAPI-Host\": \"instagram130.p.rapidapi.com\"\n",
        "}\n",
        "\n",
        "response = requests.get(url, headers=headers, params=querystring)\n",
        "\n",
        "data = response.json()\n",
        "\n",
        "# Process the data\n",
        "ai_agent_type, bio_links, fb_profile_biolink, blocked_by_viewer, country_block, external_url, external_url_linkshimmed, full_name, has_clips, highlight_reel_count, is_professional_account, category_enum = process_data(data)\n",
        "\n",
        "# Print the results\n",
        "print(f\"AI Agent Type: {ai_agent_type}\")\n",
        "print(f\"Bio Links: {bio_links}\")\n",
        "print(f\"Facebook Profile Biolink: {fb_profile_biolink}\")\n",
        "print(f\"Blocked by Viewer: {blocked_by_viewer}\")\n",
        "print(f\"Country Block: {country_block}\")\n",
        "print(f\"External URL: {external_url}\")\n",
        "print(f\"External URL Linkshimmed: {external_url_linkshimmed}\")\n",
        "print(f\"Full Name: {full_name}\")\n",
        "print(f\"Has Clips: {has_clips}\")\n",
        "print(f\"Highlight Reel Count: {highlight_reel_count}\")\n",
        "print(f\"Is Professional Account: {is_professional_account}\")\n",
        "print(f\"Category Enum: {category_enum}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OertfSp-acIC"
      },
      "outputs": [],
      "source": [
        "#CHECKING IF THE REQIREMENTS ARE THERE IN API INFO\n",
        "import requests\n",
        "\n",
        "def process_data(api_response):\n",
        "    # Extract additional information\n",
        "    ai_agent_type = api_response.get('ai_agent_type', 'Not available')\n",
        "    url = api_response.get('external_url', 'Not available')\n",
        "    country_block = api_response.get('country_block', 'Not available')\n",
        "    bio_links = api_response.get('bio_links', [])\n",
        "    fb_profile_biolink = api_response.get('fb_profile_biolink', 'Not available')\n",
        "    blocked_by_viewer = api_response.get('blocked_by_viewer', 'Not available')\n",
        "    external_url = api_response.get('external_url', 'Not available')\n",
        "    external_url_linkshimmed = api_response.get('external_url_linkshimmed', 'Not available')\n",
        "    full_name = api_response.get('full_name', 'Not available')\n",
        "    has_clips = api_response.get('has_clips', 'Not available')\n",
        "    highlight_reel_count = api_response.get('highlight_reel_count', 'Not available')\n",
        "    is_professional_account = api_response.get('is_professional_account', 'Not available')\n",
        "    category_enum = api_response.get('category_enum', 'Not available')\n",
        "\n",
        "    return ai_agent_type, url, country_block, bio_links, fb_profile_biolink, blocked_by_viewer, external_url, external_url_linkshimmed, full_name, has_clips, highlight_reel_count, is_professional_account, category_enum\n",
        "\n",
        "# Example usage\n",
        "name = input(\"Enter Instagram username: \")  # Get username from the user\n",
        "url = \"https://instagram130.p.rapidapi.com/account-info\"\n",
        "\n",
        "querystring = {\"username\": name}\n",
        "\n",
        "headers = {\n",
        "    \"X-RapidAPI-Key\": \"c1121ad9edmsh28a3e1ba931dcf9p10b968jsnd61824ad3d31\",\n",
        "    \"X-RapidAPI-Host\": \"instagram130.p.rapidapi.com\"\n",
        "}\n",
        "\n",
        "response = requests.get(url, headers=headers, params=querystring)\n",
        "\n",
        "data = response.json()\n",
        "\n",
        "# Process the data\n",
        "ai_agent_type, url, country_block, bio_links, fb_profile_biolink, blocked_by_viewer, external_url, external_url_linkshimmed, full_name, has_clips, highlight_reel_count, is_professional_account, category_enum = process_data(data)\n",
        "\n",
        "# Print the results\n",
        "print(f\"AI Agent Type: {ai_agent_type}\")\n",
        "print(f\"URL: {url}\")\n",
        "print(f\"Country Block: {country_block}\")\n",
        "print(f\"Bio Links: {bio_links}\")\n",
        "print(f\"FB Profile Biolink: {fb_profile_biolink}\")\n",
        "print(f\"Blocked by Viewer: {blocked_by_viewer}\")\n",
        "print(f\"External URL: {external_url}\")\n",
        "print(f\"External URL Linkshimmed: {external_url_linkshimmed}\")\n",
        "print(f\"Full Name: {full_name}\")\n",
        "print(f\"Has Clips: {has_clips}\")\n",
        "print(f\"Highlight Reel Count: {highlight_reel_count}\")\n",
        "print(f\"Is Professional Account: {is_professional_account}\")\n",
        "print(f\"Category Enum: {category_enum}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DY3RxG5zd44e"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'instaloader'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#COLLECTING DETAILED INFO FROM INSTALOADER\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minstaloader\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_instagram_data\u001b[39m(username):\n\u001b[0;32m      5\u001b[0m     L \u001b[38;5;241m=\u001b[39m instaloader\u001b[38;5;241m.\u001b[39mInstaloader()\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'instaloader'"
          ]
        }
      ],
      "source": [
        "#COLLECTING DETAILED INFO FROM INSTALOADER\n",
        "import instaloader\n",
        "\n",
        "def get_instagram_data(username):\n",
        "    L = instaloader.Instaloader()\n",
        "\n",
        "    try:\n",
        "        # Retrieve profile information\n",
        "        profile = instaloader.Profile.from_username(L.context, username)\n",
        "\n",
        "        # Profile pic\n",
        "        profile_pic_url = profile.profile_pic_url\n",
        "        print(f\"Profile Pic URL: {profile_pic_url}\")\n",
        "\n",
        "        # Num/length username\n",
        "        num_length_username = len(profile.username)\n",
        "        print(f\"Num/Length Username: {num_length_username}\")\n",
        "\n",
        "        # Fullname words\n",
        "        fullname_words = len(profile.full_name.split())\n",
        "        print(f\"Fullname Words: {fullname_words}\")\n",
        "\n",
        "        # Num/length fullname\n",
        "        num_length_fullname = len(profile.full_name)\n",
        "        print(f\"Num/Length Fullname: {num_length_fullname}\")\n",
        "\n",
        "        # Name==username\n",
        "        name_equals_username = 1 if profile.full_name.lower() == profile.username.lower() else 0\n",
        "        print(f\"Name==Username: {name_equals_username}\")\n",
        "\n",
        "        # Description length\n",
        "        description_length = len(profile.biography)\n",
        "        print(f\"Description Length: {description_length}\")\n",
        "\n",
        "        # External URL\n",
        "        external_url = 1 if profile.external_url else 0\n",
        "        print(f\"External URL: {external_url}\")\n",
        "\n",
        "        # Private\n",
        "        is_private = 1 if profile.is_private else 0\n",
        "        print(f\"Private: {is_private}\")\n",
        "\n",
        "        # Number of posts, followers, and follows\n",
        "        num_posts = profile.mediacount\n",
        "        num_followers = profile.followers\n",
        "        num_follows = profile.followees\n",
        "\n",
        "        print(f\"#Posts: {num_posts}\")\n",
        "        print(f\"#Followers: {num_followers}\")\n",
        "        print(f\"#Follows: {num_follows}\")\n",
        "\n",
        "    except instaloader.exceptions.ProfileNotExistsException:\n",
        "        print(f\"Profile with username {username} does not exist.\")\n",
        "\n",
        "# Example usage\n",
        "get_instagram_data(\"rusharavichandran\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnbVUlbcGrsE"
      },
      "outputs": [],
      "source": [
        "#GETTING IMPORTANT FEATURE FROM DECISION TREE\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming your dataset is stored in a CSV file named 'instagram_data.csv'\n",
        "# Replace this with the actual path to your dataset\n",
        "file_path = '/content/drive/MyDrive/HACKATHON/Datasets/insta_train.csv'\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Define features (X) and target variable (y)\n",
        "X = df.drop(columns=['fake'])  # Excluding the 'fake' column as it is the target variable\n",
        "y = df['fake']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features (optional but can be beneficial for some algorithms)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train a Decision Tree classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances = clf.feature_importances_\n",
        "\n",
        "# Print feature importances\n",
        "for feature, importance in zip(X.columns, feature_importances):\n",
        "    print(f\"{feature}: {importance}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyMpiBWWIDR5"
      },
      "outputs": [],
      "source": [
        "#GETTING IMPORTANT FEATURE FROM KBEST\n",
        "import pandas as pd\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Feature selection using SelectKBest with chi2\n",
        "k_best_features = 5  # You can adjust this number based on your requirements\n",
        "selector = SelectKBest(chi2, k=k_best_features)\n",
        "X_train_kbest = selector.fit_transform(X_train, y_train)\n",
        "X_test_kbest = selector.transform(X_test)\n",
        "\n",
        "# Train a Decision Tree classifier on the selected features\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train_kbest, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = clf.predict(X_test_kbest)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Get the indices of the selected features\n",
        "selected_feature_indices = selector.get_support(indices=True)\n",
        "\n",
        "# Print selected features\n",
        "selected_features = X.columns[selected_feature_indices]\n",
        "print(f\"Selected Features: {list(selected_features)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1YUaiI1vhdz"
      },
      "outputs": [],
      "source": [
        "#TRAINING MODEL USING DATASET\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Load your dataset\n",
        "# Replace 'your_dataset.csv' with the actual path to your dataset\n",
        "dataset_path = '/content/drive/MyDrive/HACKATHON/Datasets/insta_train.csv'\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# Define features and target\n",
        "features =['profile pic', 'nums/length username', 'name==username', 'description length', 'external URL']\n",
        "target = 'fake'\n",
        "\n",
        "X = df[features].values\n",
        "y = df[target].values\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for CNN input\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# Build CNN model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Print confusion matrix\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSuz8MeOl4kn"
      },
      "outputs": [],
      "source": [
        "#TESTING USING TEST DATASET\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Load your test dataset\n",
        "# Replace 'your_test_dataset.csv' with the actual path to your test dataset\n",
        "test_dataset_path = '/content/drive/MyDrive/HACKATHON/Datasets/insta_test.csv'\n",
        "df_test = pd.read_csv(test_dataset_path)\n",
        "\n",
        "# Define features and target\n",
        "features_test = ['profile pic', 'nums/length username', 'name==username', 'description length', 'external URL']\n",
        "target_test = 'fake'\n",
        "\n",
        "X_test_data = df_test[features_test].values\n",
        "y_test_data = df_test[target_test].values\n",
        "\n",
        "# Standardize the test data\n",
        "scaler_test = StandardScaler()\n",
        "X_test_data = scaler_test.fit_transform(X_test_data)\n",
        "\n",
        "# Reshape data for CNN input\n",
        "X_test_data = X_test_data.reshape(X_test_data.shape[0], X_test_data.shape[1], 1)\n",
        "\n",
        "# Load your trained CNN model\n",
        "# Replace 'your_model.h5' with the actual path to your saved model\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/HACKATHON/Models/your_model.h5')\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "y_pred_test = (model.predict(X_test_data) > 0.5).astype(int)\n",
        "\n",
        "# Calculate and print accuracy, classification report, and confusion matrix\n",
        "accuracy_test = accuracy_score(y_test_data, y_pred_test)\n",
        "print(f'Test Accuracy: {accuracy_test:.2f}')\n",
        "\n",
        "print('Test Classification Report:')\n",
        "print(classification_report(y_test_data, y_pred_test))\n",
        "\n",
        "print('Test Confusion Matrix:')\n",
        "print(confusion_matrix(y_test_data, y_pred_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3qeOOZHm4eo"
      },
      "outputs": [],
      "source": [
        "pip install instaloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvmN_ofQkPTG"
      },
      "outputs": [],
      "source": [
        "#GETTING BASIC DETAILS FROM USER\n",
        "import instaloader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load your trained CNN model\n",
        "# Replace 'your_model.h5' with the actual path to your saved model\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/HACKATHON/Models/your_model.h5')\n",
        "\n",
        "# Function to get Instagram data using Instaloader\n",
        "def get_instagram_data(username):\n",
        "    L = instaloader.Instaloader()\n",
        "\n",
        "    try:\n",
        "        # Retrieve profile information\n",
        "        profile = instaloader.Profile.from_username(L.context, username)\n",
        "\n",
        "        # Profile pic\n",
        "        profile_pic_url = profile.profile_pic_url\n",
        "        print(f\"Profile Pic URL: {profile_pic_url}\")\n",
        "\n",
        "        # Num/length username\n",
        "        num_length_username = len(profile.username)\n",
        "        print(f\"Num/Length Username: {num_length_username}\")\n",
        "\n",
        "        # Fullname words\n",
        "        fullname_words = len(profile.full_name.split())\n",
        "        print(f\"Fullname Words: {fullname_words}\")\n",
        "\n",
        "        # Num/length fullname\n",
        "        num_length_fullname = len(profile.full_name)\n",
        "        print(f\"Num/Length Fullname: {num_length_fullname}\")\n",
        "\n",
        "        # Name==username\n",
        "        name_equals_username = 1 if profile.full_name.lower() == profile.username.lower() else 0\n",
        "        print(f\"Name==Username: {name_equals_username}\")\n",
        "\n",
        "        # Description length\n",
        "        description_length = len(profile.biography)\n",
        "        print(f\"Description Length: {description_length}\")\n",
        "\n",
        "        # External URL\n",
        "        external_url = 1 if profile.external_url else 0\n",
        "        print(f\"External URL: {external_url}\")\n",
        "\n",
        "        # Private\n",
        "        is_private = 1 if profile.is_private else 0\n",
        "        print(f\"Private: {is_private}\")\n",
        "\n",
        "        # Number of posts, followers, and follows\n",
        "        num_posts = profile.mediacount\n",
        "        num_followers = profile.followers\n",
        "        num_follows = profile.followees\n",
        "\n",
        "        print(f\"#Posts: {num_posts}\")\n",
        "        print(f\"#Followers: {num_followers}\")\n",
        "        print(f\"#Follows: {num_follows}\")\n",
        "\n",
        "        return [external_url, num_length_username, name_equals_username, description_length, external_url]\n",
        "\n",
        "    except instaloader.exceptions.ProfileNotExistsException:\n",
        "        print(f\"Profile with username {username} does not exist.\")\n",
        "        return [0, 0, 0, 0, 0]\n",
        "\n",
        "# Example usage\n",
        "username = \"rusharavichandran\"\n",
        "instagram_data = get_instagram_data(username)\n",
        "\n",
        "# Reshape data for CNN input\n",
        "instagram_data = np.array(instagram_data).reshape(1, -1, 1)\n",
        "\n",
        "# Predict using the model\n",
        "prediction = (model.predict(instagram_data) > 0.5).astype(int)\n",
        "print(f'Prediction for {username}: {prediction[0][0]}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8fBNyfIhbFV"
      },
      "outputs": [],
      "source": [
        "#TESTING USING USER INPUT\n",
        "import instaloader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Function to get Instagram data using Instaloader\n",
        "def get_instagram_data(username):\n",
        "    L = instaloader.Instaloader()\n",
        "\n",
        "    try:\n",
        "        # Retrieve profile information\n",
        "        profile = instaloader.Profile.from_username(L.context, username)\n",
        "\n",
        "        # Profile pic\n",
        "        profile_pic_url = profile.profile_pic_url\n",
        "        print(f\"Profile Pic URL: {profile_pic_url}\")\n",
        "\n",
        "        # Num/length username\n",
        "        num_length_username = len(profile.username)\n",
        "        print(f\"Num/Length Username: {num_length_username}\")\n",
        "\n",
        "        # Fullname words\n",
        "        fullname_words = len(profile.full_name.split())\n",
        "        print(f\"Fullname Words: {fullname_words}\")\n",
        "\n",
        "        # Num/length fullname\n",
        "        num_length_fullname = len(profile.full_name)\n",
        "        print(f\"Num/Length Fullname: {num_length_fullname}\")\n",
        "\n",
        "        # Name==username\n",
        "        name_equals_username = 1 if profile.full_name.lower() == profile.username.lower() else 0\n",
        "        print(f\"Name==Username: {name_equals_username}\")\n",
        "\n",
        "        # Description length\n",
        "        description_length = len(profile.biography)\n",
        "        print(f\"Description Length: {description_length}\")\n",
        "\n",
        "        # External URL\n",
        "        external_url = 1 if profile.external_url else 0\n",
        "        print(f\"External URL: {external_url}\")\n",
        "\n",
        "        # Private\n",
        "        is_private = 1 if profile.is_private else 0\n",
        "        print(f\"Private: {is_private}\")\n",
        "\n",
        "        # Number of posts, followers, and follows\n",
        "        num_posts = profile.mediacount\n",
        "        num_followers = profile.followers\n",
        "        num_follows = profile.followees\n",
        "\n",
        "        print(f\"#Posts: {num_posts}\")\n",
        "        print(f\"#Followers: {num_followers}\")\n",
        "        print(f\"#Follows: {num_follows}\")\n",
        "\n",
        "        return [external_url, num_length_username, name_equals_username, description_length, external_url]\n",
        "\n",
        "    except instaloader.exceptions.ProfileNotExistsException:\n",
        "        print(f\"Profile with username {username} does not exist.\")\n",
        "        return [0, 0, 0, 0, 0]\n",
        "\n",
        "# Example usage\n",
        "username= input(\"Enter Instagram username: \")\n",
        "instagram_data = get_instagram_data(username)\n",
        "\n",
        "# Reshape data for CNN input\n",
        "instagram_data = np.array(instagram_data).reshape(1, -1, 1)\n",
        "\n",
        "# Load your trained CNN model\n",
        "# Replace 'your_model.h5' with the actual path to your saved model\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/HACKATHON/Models/your_model.h5')\n",
        "\n",
        "# Predict using the model\n",
        "prediction = (model.predict(instagram_data) > 0.5).astype(int)\n",
        "print(f'Prediction for {username}: {prediction[0][0]}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aPTmgyKNV6W"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Load your dataset\n",
        "# Replace 'your_dataset.csv' with the actual path to your dataset\n",
        "dataset_path = '/content/drive/MyDrive/HACKATHON/Datasets/insta_train.csv'\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# Define features and target\n",
        "features = ['profile pic', 'nums/length username', 'name==username', 'description length', 'external URL']\n",
        "target = 'fake'\n",
        "\n",
        "# Function to get Instagram features\n",
        "def get_instagram_features(username):\n",
        "    url = \"https://instagram130.p.rapidapi.com/account-info\"\n",
        "    querystring = {\"username\": username}\n",
        "    headers = {\n",
        "        \"X-RapidAPI-Key\": \"c1121ad9edmsh28a3e1ba931dcf9p10b968jsnd61824ad3d31\",\n",
        "        \"X-RapidAPI-Host\": \"instagram130.p.rapidapi.com\"\n",
        "    }\n",
        "    response = requests.get(url, headers=headers, params=querystring)\n",
        "    data = response.json()\n",
        "    if \"username\" in data:\n",
        "        return [data['profile_pic'], len(data['username']), int(data['username'] == data['full_name']),\n",
        "                len(data['description']), int(bool(data['external_url']))]\n",
        "    else:\n",
        "        return [0, 0, 0, 0, 0]\n",
        "\n",
        "# Apply the Instagram API function to each row in the DataFrame\n",
        "df['instagram_features'] = df['username'].apply(get_instagram_features)\n",
        "\n",
        "# Extract features from the new 'instagram_features' column\n",
        "df[features] = pd.DataFrame(df['instagram_features'].tolist(), index=df.index)\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df.drop(['instagram_features'], axis=1, inplace=True)\n",
        "\n",
        "# Define X and y\n",
        "X = df[features].values\n",
        "y = df[target].values\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for CNN input\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# Build CNN model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Print confusion matrix\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5lXIUxIfzTj"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "0.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
